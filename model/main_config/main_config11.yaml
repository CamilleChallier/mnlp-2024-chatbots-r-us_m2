"team_name": "Chatbots-R-Us" # Your team name
"eval_method": ["reward"] # mcqa, reward, rag, compression
"task_type": "seq2seq" # causal_lm, seq2seq
"policy_model_path": "./checkpoints/bart-base_LoRA_dpo-M1-orca-webgpt_bs-8_max-len-512_lr-1e-4/checkpoint-17097" # Your path to the final checkpoint
"reference_model_path": "./checkpoints/bart-base" # The repo id of your pretrained reference model
"quantized_policy_model_path": "./checkpoints/best_model_quantized/" # Your path to the final quantized checkpoint
"rag_policy_model_path": "./datasets/dpo_webgpt_comparaisons_test.jsonl" # Your path to the final RAG checkpoint "./checkpoints/best_model_rag/"
"test_data_path": "./datasets/dpo_M1_all_pairs_length-sup-200-char_test.jsonl" #Your path to the test data 
"dpo_model_args": {"beta" : 0.1} # Put any model arguments required to load your DPO model below
"rag_model_args": # Put any model arguments required to load your rag model below
  "encoder_model_path": "facebook/bart-large"
  "retriever_model_path": "./checkpoints/rag_retriever"
  "document_dir": "./data/documents"
"quantized_model_args": null # Put any model arguments required to load your quantized model below
